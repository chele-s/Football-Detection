============================================
RF-DETR FOOTBALL PIPELINE — PRODUCTION PLAYBOOK
============================================

1. Overview
-----------
- Entry point: `run_mjpeg_stream.py`. It loads `configs/model_config.yml` and `configs/stream_config.yml`, decodes a 4K source, downsamples for RF-DETR inference, applies tracking/virtual camera, then upscales back to the target output.
- Output: MJPEG server on `http://localhost:8554/stream.mjpg`. Keep this port private (localhost or SSH tunnel). Use a lightweight proxy only if remote viewing is mandatory.

2. Hardware & OS Requirements
-----------------------------
- NVIDIA GPU with CUDA 11+ and exposed NVDEC/NVENC engines (RTX 5090, L4, L40S, A10G, etc.).
- Ubuntu 22.04/24.04 with matching NVIDIA driver versions between host and container (validate with `nvidia-smi`).
- Python 3.10 (PyNvCodec does not yet support 3.12). Minimum 100 GB SSD/NVMe free for videos and MJPEG segments.

3. Environment Setup
--------------------
```bash
sudo apt update && sudo apt install -y python3.10-venv git tmux ffmpeg
git clone https://github.com/<org>/Football-Detection.git
cd Football-Detection
python3.10 -m venv rf-detr-venv-310
source rf-detr-venv-310/bin/activate
pip install --upgrade pip
pip install -r requirements.txt
bash scripts/install_pynvcodec.sh      # ensures PyNvCodec + CMake pin
export LD_LIBRARY_PATH=/usr/lib/x86_64-linux-gnu:$LD_LIBRARY_PATH
```
Keep these commands in `scripts/setup_env.sh` for reproducible hosts.

4. GPU Readiness Checklist
--------------------------
Run these before every deployment:
```bash
nvidia-smi
python guides/verify_gpu_setup.py
python diagnose_gpu.py  # optional extended report
```
If you see `Driver/library version mismatch` or `unsupported device (2)`:
1) reinstall the matching `nvidia-utils-*` package, 2) ensure the container/runtime exposes `video` capability, 3) rerun the diagnostics.

5. Configuration Management
---------------------------
- `configs/model_config.yml`: checkpoint path, confidence/IoU thresholds, device, half-precision flag, etc.
- `configs/stream_config.yml`: input URL, target FPS, bitrate/preset, output resolution, detection resolution (e.g., 1080p or 720p), camera smoothing parameters.
Version these files (or store overrides in AWS SSM/Secrets). The server merges model + stream configs automatically.

5.1 Using YouTube Sources
-------------------------
You can feed a YouTube match directly into the pipeline. Since YouTube URLs expire, prefer one of these methods:

**A) On-demand direct media URL**
1. Resolve the actual media link:
   ```bash
   yt-dlp -g -f best https://www.youtube.com/watch?v=<VIDEO_ID>
   ```
2. Copy the HTTPS URL returned by `yt-dlp` and set it as `stream.input_url` in `configs/stream_config.yml`.
3. Launch `run_mjpeg_stream.py` normally. Re-run `yt-dlp -g` if the link expires.

**B) Stable local restream (recommended for live events)**
1. Pipe YouTube into ffmpeg and rebroadcast locally:
   ```bash
   yt-dlp -f best -o - https://www.youtube.com/watch?v=<VIDEO_ID> \
     | ffmpeg -re -i - -c copy -f mpegts udp://127.0.0.1:9000
   ```
2. Set `stream.input_url: "udp://127.0.0.1:9000"`.
3. Start the pipeline; it now reads from the local UDP endpoint, so the feed continues even if the original URL rotates.

Both approaches keep the rest of the pipeline (downscale → RF-DETR → upscale → MJPEG) unchanged.

6. Launching the Pipeline
-------------------------
```bash
tmux new -s stream
source rf-detr-venv-310/bin/activate
python run_mjpeg_stream.py --config configs/stream_config.yml
```
Watch for the boot log:
1. `[1/5] Loading configurations`
2. `[2/5] Loading RF-DETR model`
3. `[3/5] Initializing tracker`
4. `[4/5] Starting MJPEG server on port 8554`
5. `[5/5] Opening video source`

When you see `MJPEG server started! http://localhost:8554/stream.mjpg`, the stream is live.

7. Monitoring & Viewing
-----------------------
- Local health: monitor console logs for `[STREAM] Frame ...` FPS stats. Use `tmux capture-pane -S -100` to grab the last lines.
- Remote viewing (safe):
  ```bash
  ssh -N -L 8554:localhost:8554 user@server
  ```
  Then open `http://localhost:8554/stream.mjpg` in VLC/Chrome.
- Optional low-bitrate proxy: run a second ffmpeg that scales to 1280×480@10 fps and exposes another localhost port for remote monitoring.

8. Recording Without FPS Drops
------------------------------
- **Zero-reencode capture (preferred):**
  ```bash
  ffmpeg -thread_queue_size 2048 \
         -i http://localhost:8554/stream.mjpg \
         -c copy -f segment -segment_time 60 clips/clip_%03d.mjpeg
  ```
  Converts to MP4 offline: `ffmpeg -i clip_000.mjpeg -c:v libx264 -preset faster -crf 20 clip_000.mp4`.
- **Hardware encode (when NVENC available):**
  ```bash
  ffmpeg -thread_queue_size 512 \
         -i http://localhost:8554/stream.mjpg \
         -c:v h264_nvenc -preset p5 -cq 19 -b_ref_mode middle output_4k.mp4
  ```
- Keep recordings on NVMe and rotate via cron (`find clips -mtime +2 -delete`).

9. Troubleshooting Quick Reference
----------------------------------
- `CUDA_ERROR_NO_DEVICE` / `unsupported device (2)`: the GPU runtime lacks video capabilities. Recreate the VM with NVENC/NVDEC enabled or load the correct driver packages.
- MJPEG server stuck at 10–15 fps: an external client is pulling the 4K stream over a slow link; keep port 8554 private and rely on local recording or a downscaled proxy.
- `torch.jit.trace` warnings: we already disable compile via `optimize_for_inference(compile=False)`; do not enable `torch.compile()` for RF-DETR unless you re-test thoroughly.
- Import errors (`Inference` vs `inference`): handled automatically in `app/__init__.py`, but if you move files, maintain case-consistent names.

10. Production Hygiene & Automation
-----------------------------------
- Wrap the startup sequence in `scripts/start_pipeline.sh` (activate venv, run diagnostics, launch python).
- Use systemd or tmuxp to auto-restart on crash and keep logs in `/var/log/football-stream/stream.log`.
- Store configs and model artifacts in object storage (S3/GCS) and sync during deployment.
- Keep `guides/PRODUCTION_GUIDE.md` and this `instruccion.txt` updated whenever you change dependencies, driver versions, or inference parameters.

With this playbook you can rebuild the entire Vast.ai environment on AWS, bare metal, or any GPU node while preserving the exact behavior (downscale inference, 4K output, secure MJPEG access, and safe recording).
